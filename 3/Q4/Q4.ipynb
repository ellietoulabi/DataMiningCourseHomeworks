{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "different-workshop",
   "metadata": {},
   "source": [
    "<h1 style=\"direction:rtl;text-align:center;font-family:Yekan, sans-serif;color:#ffffff;background-color:#cca3db;font-size:48p\"><strong>سوال چهارم</strong> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "damaged-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "circular-attachment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T3_resin</th>\n",
       "      <th>Serum_thyroxin</th>\n",
       "      <th>Serum_triiodothyronine</th>\n",
       "      <th>Basal_TSH</th>\n",
       "      <th>Abs_diff_TSH</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T3_resin Serum_thyroxin Serum_triiodothyronine Basal_TSH  Abs_diff_TSH  \\\n",
       "0     107.0           10.1                    2.2       0.9           2.7   \n",
       "1       NaN            9.9                    3.1       2.0           5.9   \n",
       "2     127.0           12.9                    2.4       NaN           0.6   \n",
       "3     109.0            NaN                    1.6       1.4           1.5   \n",
       "4     105.0            7.3                    1.5       NaN          -0.1   \n",
       "\n",
       "   Outcome  \n",
       "0      1.0  \n",
       "1      1.0  \n",
       "2      1.0  \n",
       "3      1.0  \n",
       "4      1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('thyroid.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-reason",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;color:#945aaf;background-color:#ffffff;font-size:48p\"><strong> a) </strong></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wired-meaning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape :  (185, 6)\n",
      "Test shape :     (37, 6)\n",
      "Train shape :    (148, 6)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size = 0.2, random_state = 7)\n",
    "df_train.to_csv('train.csv',index=False)\n",
    "df_test.to_csv('test.csv',index=False)\n",
    "\n",
    "print('Dataset shape : ',df.shape)\n",
    "print('Test shape :    '   ,df_test.shape)\n",
    "print('Train shape :   '  ,df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-ecology",
   "metadata": {},
   "source": [
    "<h4 style=\"direction:rtl;text-align:right;font-family:Yekan, sans-serif;color:#945aaf;background-color:#ffffff;font-size:48p\"><strong>شرح کد :</strong> </h4>\n",
    "\n",
    "<p style=\"direction:rtl;text-align:right;\">ابتدا به کمک تابع train_test_split دیتاست را به دو دسته آموزش و تست تقسیم می کنیم به طوری که 0.2 داده ها تست و بقیه آموزش باشند و آنها را در فایلهای جدا ذخیره می کنیم. </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-enhancement",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;color:#945aaf;background-color:#ffffff;font-size:48p\"><strong> b) </strong></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-netherlands",
   "metadata": {},
   "source": [
    "<h4 style=\"direction:rtl;text-align:right;font-family:Yekan, sans-serif;color:#945aaf;background-color:#ffffff;font-size:48p\"><strong> پاسخ :</strong> </h4>\n",
    "\n",
    "<p style=\"direction:rtl;text-align:right;\">پارامتر stratify نسبت فیچر هدف در دیتاست اصلی را در دو دیتاست آموزش و تست هم همانطور حفظ می کند.برای مثال اگر متغیر هدف ما در دیتاستی دو کلاس A و B داشته باشد که 60درصد رکوردهاA و 40 درصد B باشند و آن را به دو مجموعه آموزش و تست تقسیم کنیم به طوری که 90درصد داده ها آموزش و 10درصد تست باشند این نسبت 60 و 40 هم در داده های تست برقرار است هم آموزش.\n",
    "غالباً می خواهیم نسبت داده ها را برای پیش بینی بهتر و تکرارپذیری نتایج حفظ کنیم.\n",
    "</p>\n",
    "\n",
    "<p style=\"direction:rtl;text-align:right;\">روش استفاده از آن به این صورت است که stratify=y و y یک آرایه است که می خواهیم نسبت تقسیم مانند آن توزیع شود مثلا به جای y می توان ستون متغیر هدف را قرار داد.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-emission",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;color:#945aaf;background-color:#ffffff;font-size:48p\"><strong> c) </strong></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "attached-schedule",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome\n",
      "1.0    115\n",
      "2.0     22\n",
      "Name: Outcome, dtype: int64\n",
      "1 Proportion =  0.8394160583941606\n",
      "2 Proportion =  0.16058394160583941\n"
     ]
    }
   ],
   "source": [
    "print(df_train.groupby('Outcome')['Outcome'].count())\n",
    "one = df_train.groupby('Outcome')['Outcome'].count().iloc[0]\n",
    "two = df_train.groupby('Outcome')['Outcome'].count().iloc[1]\n",
    "print('1 Proportion = ',one/(one+two))\n",
    "print('2 Proportion = ',two/(one+two))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "twelve-montgomery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Proportion =  0.7837837837837838\n",
      "2 Proportion =  0.21621621621621623\n"
     ]
    }
   ],
   "source": [
    "df_test.groupby('Outcome')['Outcome'].count()\n",
    "one = df_test.groupby('Outcome')['Outcome'].count().iloc[0]\n",
    "two = df_test.groupby('Outcome')['Outcome'].count().iloc[1]\n",
    "print('1 Proportion = ',one/(one+two))\n",
    "print('2 Proportion = ',two/(one+two))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-conversion",
   "metadata": {},
   "source": [
    "<h4 style=\"direction:rtl;text-align:right;font-family:Yekan, sans-serif;color:#945aaf;background-color:#ffffff;font-size:48p\"><strong> پاسخ :</strong> </h4>\n",
    "\n",
    "<p style=\"direction:rtl;text-align:right;\">خیر به صورت یکسان توزیع نشده اند و این را از اعداد فوق میتوان فهمید.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-litigation",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;color:#945aaf;background-color:#ffffff;font-size:48p\"><strong> d) </strong></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-police",
   "metadata": {},
   "source": [
    "<h4 style=\"direction:rtl;text-align:right;font-family:Yekan, sans-serif;color:#945aaf;background-color:#ffffff;font-size:48p\"><strong> پاسخ :</strong> </h4>\n",
    "\n",
    "<p style=\"direction:rtl;text-align:right;\">روش های مختلفی برای برخورد با دیتاست های imbalanced وجود دارد مانند :\n",
    "    <ol>\n",
    "        <li>Resample the training set</li>\n",
    "        <li>Use K-fold Cross-Validation in the right way</li>\n",
    "        <li>Ensemble different resampled datasets</li>\n",
    "        <li>Resample with different ratios</li>\n",
    "        <li>Cluster the abundant class</li>\n",
    "        <li>Design your own models</li>\n",
    "        <li>Use the right evaluation metrics</li>   \n",
    "    </ol>\n",
    "</p>\n",
    "<p style=\"direction:rtl;text-align:right;\"> <strong>روش اول(Resample the training set)</strong>\n",
    "</p>\n",
    "<p style=\"direction:rtl;text-align:right;\">دو روش برای تبدیل دیتاست imbalanced به بالانس وجود دارد.</p>\n",
    "<p style=\"direction:rtl;text-align:right;\"><strong>Under-sampling</strong> که با کاهش اندازه کلاس با فراوانی بالا ، مجموعه داده را متعادل می کند. این روش هنگامی استفاده می شود که مقدار داده کافی باشد. با نگه داشتن همه نمونه ها در کلاس با فراوانی کم و انتخاب تصادفی تعداد مساوی از نمونه ها در کلاس فراوان ، می توان یک مجموعه داده جدید و متعادل را برای مدلسازی بهتر ایجاد کرد. </p>\n",
    "<p style=\"direction:rtl;text-align:right;\"><strong>Over-sampling</strong>در صورت ناکافی بودن مقدار داده ، ازاین نمونه برداری استفاده می شود. این روش سعی دارد با افزایش اندازه نمونه های با فراوانی کم ، مجموعه داده ها را متعادل کند. به جای خلاص شدن از شر نمونه های فراوان ، نمونه های مشابه نمونه ها با فراوانی کم جدید با استفاده از تکرار ، بوت استرپ یا SMOTE (Synthetic Minority Over-Sampling Technique) تولید می کنیم.\n",
    "</p>\n",
    "<p style=\"direction:rtl;text-align:right;\">\n",
    "هیچکدام ار این دو روش نسبت به هم برتری ندارد. کاربرد این دو روش بستگی به مورد استفاده در آن و خود مجموعه داده دارد. ترکیبی از  این دو روش نمونه برداری نیز اغلب موفق است.\n",
    "\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"direction:rtl;text-align:right;\"> <strong>روش دوم(Use the right evaluation metrics)</strong>\n",
    "</p>\n",
    "<p style=\"direction:rtl;text-align:right;\">استفاده از معیارهای ارزیابی نامناسب برای مدل تولید شده با استفاده از داده های نامتعادل می تواند خطرناک باشد.مثلا وثتی 100000داده داریم که 10تا در کلاسA و بقیه در کلاس B قرار میگیرند accuracy مدلی که همه را در کلاسB پیش بینی کند خیلی بالا خواهد بود در حالی که مدل ارزشمندی نیست. در این حالت می توان معیارهای ارزیابی جایگزین دیگری مانند:\n",
    "</p>\n",
    "\n",
    "<p style=\"direction:rtl;text-align:right;\">1- Precision/Specificity یعنی چندتا از نمونه های انتخاب شده مرتبط هستند.</p>\n",
    "<p style=\"direction:rtl;text-align:right;\">2- Recall/Sensitivity یعنی چه تعداد از نمونه های مرتبط انتخاب شده اند.</p>\n",
    "<p style=\"direction:rtl;text-align:right;\">3- F1 score که میانگین هارمونیک دقت و recall است</p>\n",
    "<p style=\"direction:rtl;text-align:right;\">4-  MCC که ضریب همبستگی بین طبقه بندی باینری مشلهده شده و پیش بینی شده است.</p>\n",
    "<p style=\"direction:rtl;text-align:right;\">5- AUC که رابطه بین نرخ true-positive و false-positive است.</p>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
